{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8562132",
   "metadata": {},
   "source": [
    "# Random Forest Regression on kc_house_data_encoded_tree_step3\n",
    "\n",
    "Workflow:\n",
    "1. Setup and Imports\n",
    "2. Model Hypothesis\n",
    "3. Load Dataset\n",
    "4. Prepare Features and Target\n",
    "5. Train/Test Split\n",
    "6. Baseline Random Forest (sklearn)\n",
    "7. Cross Validation\n",
    "8. Convert RF to PyTorch Model (running on GPU/MPS)\n",
    "9. Best Model Testing (GPU)\n",
    "10. Test Set Evaluation (GPU)\n",
    "11. Feature Importance\n",
    "12. Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f2bc7",
   "metadata": {},
   "source": [
    "# 1. SETUP AND IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af6a90bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from hummingbird.ml import convert\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_pred, label=\"\"):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE : {mae:.4f}\")\n",
    "    print(f\"R^2 : {r2:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8a262",
   "metadata": {},
   "source": [
    "# 2. MODEL PERFORMANCE HYPOTHESIS\n",
    "Hypothesis:\n",
    "- A Random Forest Regressor on the tree-encoded dataset should capture\n",
    "  nonlinear relationships and interactions between features more effectively\n",
    "  than a linear model on the same log_price target.\n",
    "- We expect:\n",
    "    - Higher test R^2 than the linear baseline (potentially > 0.80),\n",
    "    - Lower RMSE in log_price space,\n",
    "    - Better robustness to outliers and complex patterns.\n",
    "- Hyperparameter tuning (n_estimators, max_depth, etc.) should yield\n",
    "  modest but meaningful improvements in cross-validated performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5621c42",
   "metadata": {},
   "source": [
    "# 3. LOAD ENCODED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f294cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (21613, 26)\n",
      "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  view  \\\n",
      "0         3       1.00         1180      5650     1.0           0     0   \n",
      "1         3       2.25         2570      7242     2.0           0     0   \n",
      "2         2       1.00          770     10000     1.0           0     0   \n",
      "3         4       3.00         1960      5000     1.0           0     0   \n",
      "4         3       2.00         1680      8080     1.0           0     0   \n",
      "\n",
      "   condition  grade  sqft_above  ...  sqft_lot15  sale_year  \\\n",
      "0          3      7        1180  ...        5650       2014   \n",
      "1          3      7        2170  ...        7639       2014   \n",
      "2          3      6         770  ...        8062       2015   \n",
      "3          5      7        1050  ...        5000       2014   \n",
      "4          3      8        1680  ...        7503       2015   \n",
      "\n",
      "   yr_since_renovated  log_price  is_renovated  house_age  house_age_bin  \\\n",
      "0                 NaN  12.309987             0         59            3.0   \n",
      "1                23.0  13.195616             1         63            3.0   \n",
      "2                 NaN  12.100718             0         82            3.0   \n",
      "3                 NaN  13.311331             0         49            2.0   \n",
      "4                 NaN  13.142168             0         28            2.0   \n",
      "\n",
      "   basement_ratio  above_ratio  lot_living_ratio  \n",
      "0        0.000000     1.000000          4.788136  \n",
      "1        0.155642     0.844358          2.817899  \n",
      "2        0.000000     1.000000         12.987013  \n",
      "3        0.464286     0.535714          2.551020  \n",
      "4        0.000000     1.000000          4.809524  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/kc_house_data_encoded_tree_step3.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210a1e3",
   "metadata": {},
   "source": [
    "# 4. PREPARE FEATURES AND TARGET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06b4f6a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object columns in X (should ideally be none for tree-encoded data): []\n",
      "X shape: (21613, 25)\n",
      "y shape: (21613,)\n"
     ]
    }
   ],
   "source": [
    "target_col = \"log_price\"\n",
    "\n",
    "# Sanity check: make sure target exists\n",
    "assert target_col in df.columns, f\"{target_col} not found in dataset columns.\"\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].values\n",
    "\n",
    "object_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(\"Object columns in X (should ideally be none for tree-encoded data):\", object_cols)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bca5b",
   "metadata": {},
   "source": [
    "# 5. TRAIN/TEST SPLIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "614f8275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (17290, 25)\n",
      "X_test shape: (4323, 25)\n",
      "y_train shape: (17290,)\n",
      "y_test shape: (4323,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2fd5d",
   "metadata": {},
   "source": [
    "# 6. BASELINE RANDOM FOREST (CPU TRAINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2f509245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Baseline RF Train ---\n",
      "RMSE: 0.0660\n",
      "MAE : 0.0458\n",
      "R^2 : 0.9842\n",
      "\n",
      "--- Baseline RF Test ---\n",
      "RMSE: 0.1761\n",
      "MAE : 0.1250\n",
      "R^2 : 0.8912\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=40,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "train_pred = rf.predict(X_train)\n",
    "test_pred = rf.predict(X_test)\n",
    "\n",
    "print_metrics(y_train, train_pred, \"Baseline RF Train\")\n",
    "print_metrics(y_test, test_pred, \"Baseline RF Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6140ec",
   "metadata": {},
   "source": [
    "# 7. CROSS VALIDATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c62604a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BASELINE RANDOM FOREST 5-FOLD CV ===\n",
      "RMSE: mean=0.1766, std=0.0021\n",
      "MAE : mean=0.1242, std=0.0017\n",
      "R^2 : mean=0.8875, std=0.0038\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "cv_rmse_baseline = -cross_val_score(\n",
    "    baseline_rf,\n",
    "    X,\n",
    "    y,\n",
    "    cv=kf,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "cv_mae_baseline = -cross_val_score(\n",
    "    baseline_rf,\n",
    "    X,\n",
    "    y,\n",
    "    cv=kf,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    ")\n",
    "cv_r2_baseline = cross_val_score(\n",
    "    baseline_rf,\n",
    "    X,\n",
    "    y,\n",
    "    cv=kf,\n",
    "    scoring=\"r2\",\n",
    ")\n",
    "\n",
    "print(\"=== BASELINE RANDOM FOREST 5-FOLD CV ===\")\n",
    "print(f\"RMSE: mean={cv_rmse_baseline.mean():.4f}, std={cv_rmse_baseline.std():.4f}\")\n",
    "print(f\"MAE : mean={cv_mae_baseline.mean():.4f}, std={cv_mae_baseline.std():.4f}\")\n",
    "print(f\"R^2 : mean={cv_r2_baseline.mean():.4f}, std={cv_r2_baseline.std():.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d175a2",
   "metadata": {},
   "source": [
    "# 8. CONVERT SKLEARN RF â†’ PYTORCH RF (FOR GPU INFERENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea57a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Random Forest GridSearchCV...\n",
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/girithc/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 32\u001b[0m\n\u001b[1;32m     22\u001b[0m rf_grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m     23\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mrf_pipeline,\n\u001b[1;32m     24\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     29\u001b[0m )\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting Random Forest GridSearchCV...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mrf_grid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== RANDOM FOREST GRID SEARCH RESULTS ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest params:\u001b[39m\u001b[38;5;124m\"\u001b[39m, rf_grid\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m~/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1024\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1018\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1019\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1020\u001b[0m     )\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1024\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1571\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1571\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    964\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    965\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    966\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    967\u001b[0m         )\n\u001b[1;32m    968\u001b[0m     )\n\u001b[0;32m--> 970\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    981\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    984\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    985\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    989\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    993\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/sklearn/utils/parallel.py:77\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     72\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     73\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     74\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     76\u001b[0m )\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/joblib/parallel.py:2072\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2068\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2069\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/joblib/parallel.py:1682\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1682\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1685\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1687\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1688\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/morro/255-proj/venv/lib/python3.9/site-packages/joblib/parallel.py:1800\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_ordered:\n\u001b[1;32m   1790\u001b[0m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1795\u001b[0m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[1;32m   1796\u001b[0m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1798\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING\n\u001b[1;32m   1799\u001b[0m     ):\n\u001b[0;32m-> 1800\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1801\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1804\u001b[0m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[1;32m   1805\u001b[0m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1811\u001b[0m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[1;32m   1812\u001b[0m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"\\nConverting Random Forest to PyTorch (MPS)...\")\n",
    "\n",
    "hb_model = convert(rf, \"pytorch\", X_train)\n",
    "\n",
    "hb_model.to(device)\n",
    "\n",
    "print(\"Conversion complete. Model is now on:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817f451",
   "metadata": {},
   "source": [
    "# 9. GPU PREDICTION (MPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d62c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRunning predictions on MPS...\")\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32, device=device)\n",
    "gpu_preds = hb_model.predict(X_test_tensor).cpu().numpy()\n",
    "\n",
    "print_metrics(y_test, gpu_preds, \"MPS RF Test (log_price)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdc422",
   "metadata": {},
   "source": [
    "# 10. TEST SET EVALUATION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21761be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=gpu_preds, alpha=0.4)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
    "plt.xlabel(\"Actual log_price\")\n",
    "plt.ylabel(\"Predicted log_price\")\n",
    "plt.title(\"Actual vs Predicted (MPS Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "residuals = y_test - gpu_preds\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, kde=True, bins=40)\n",
    "plt.title(\"Residual Distribution (MPS RF)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7937dc4",
   "metadata": {},
   "source": [
    "# 11. FEATURE IMPORTANCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feat_imp = pd.DataFrame({\"feature\": X.columns, \"importance\": importances})\n",
    "feat_imp = feat_imp.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"Top 20 features:\")\n",
    "print(feat_imp.head(20))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=feat_imp.head(20), x=\"importance\", y=\"feature\")\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f6762",
   "metadata": {},
   "source": [
    "# 12. HYPOTHESIS TESTING AND FINAL SUMMARY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ec24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_r2_best = r2_score(y_test, y_test_pred_best)\n",
    "test_rmse_best = np.sqrt(mean_squared_error(y_test, y_test_pred_best))\n",
    "\n",
    "print(\"\\n=== HYPOTHESIS TESTING & SUMMARY ===\")\n",
    "print(f\"Best model: {best_model_name}\")\n",
    "print(f\"Test R^2 (log_price): {test_r2_best:.4f}\")\n",
    "print(f\"Test RMSE (log_price): {test_rmse_best:.4f}\")\n",
    "\n",
    "if test_r2_best >= 0.80:\n",
    "    print(\n",
    "        \"- The Random Forest achieves strong predictive performance (R^2 >= 0.80), \"\n",
    "        \"supporting the hypothesis that tree-based models capture nonlinear patterns \"\n",
    "        \"beyond what linear regression can model.\"\n",
    "    )\n",
    "else:\n",
    "    print(\n",
    "        \"- The Random Forest does not reach the expected R^2 >= 0.80; \"\n",
    "        \"either the relationships are still too complex/noisy or further tuning/feature \"\n",
    "        \"engineering is required.\"\n",
    "    )\n",
    "\n",
    "improvement = baseline_cv_rmse_mean - rf_tuned_cv_rmse_mean\n",
    "print(\n",
    "    f\"- CV RMSE improvement of tuned RF vs baseline RF: {improvement:.4f} \"\n",
    "    \"(positive = improvement).\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"- Feature importance analysis highlights which predictors the Random Forest \"\n",
    "    \"relies on most (e.g., living area, grade, neighborhood effects, latitude, etc.).\"\n",
    ")\n",
    "print(\n",
    "    \"- Compared to linear models, Random Forests trade some interpretability for \"\n",
    "    \"potentially better accuracy and robustness to nonlinearity and interactions.\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
