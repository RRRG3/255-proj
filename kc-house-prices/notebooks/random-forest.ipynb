{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8562132",
   "metadata": {},
   "source": [
    "# Random Forest Regression on kc_house_data_encoded_tree_step3\n",
    "\n",
    "Workflow:\n",
    "1. Setup and Imports\n",
    "2. Model Hypothesis\n",
    "3. Load Dataset\n",
    "4. Prepare Features and Target\n",
    "5. Train/Test Split\n",
    "6. Baseline Random Forest (sklearn)\n",
    "7. Cross Validation\n",
    "8. Convert RF to PyTorch Model (running on GPU/MPS)\n",
    "9. Best Model Testing (GPU)\n",
    "10. Test Set Evaluation (GPU)\n",
    "11. Feature Importance\n",
    "12. Summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f2bc7",
   "metadata": {},
   "source": [
    "# 1. SETUP AND IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a90bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.10' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '/opt/homebrew/bin/python3.13 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "from hummingbird.ml import convert\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n\nRANDOM_STATE = 42\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "def print_metrics(y_true, y_pred, label=\"\"):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "    print(f\"--- {label} ---\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"MAE : {mae:.4f}\")\n",
    "    print(f\"R^2 : {r2:.4f}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a8a262",
   "metadata": {},
   "source": [
    "# 2. MODEL PERFORMANCE HYPOTHESIS\n",
    "Hypothesis:\n",
    "- A Random Forest Regressor on the tree-encoded dataset should capture\n",
    "  nonlinear relationships and interactions between features more effectively\n",
    "  than a linear model on the same log_price target.\n",
    "- We expect:\n",
    "    - Higher test R^2 than the linear baseline (potentially > 0.80),\n",
    "    - Lower RMSE in log_price space,\n",
    "    - Better robustness to outliers and complex patterns.\n",
    "- Hyperparameter tuning (n_estimators, max_depth, etc.) should yield\n",
    "  modest but meaningful improvements in cross-validated performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5621c42",
   "metadata": {},
   "source": [
    "# 3. LOAD ENCODED DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f294cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/kc_house_data_encoded_tree_step3.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210a1e3",
   "metadata": {},
   "source": [
    "# 4. PREPARE FEATURES AND TARGET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b4f6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"log_price\"\n",
    "\n",
    "# Sanity check: make sure target exists\n",
    "assert target_col in df.columns, f\"{target_col} not found in dataset columns.\"\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col].values\n",
    "\n",
    "object_cols = X.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(\"Object columns in X (should ideally be none for tree-encoded data):\", object_cols)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2bca5b",
   "metadata": {},
   "source": [
    "# 5. TRAIN/TEST SPLIT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad2fd5d",
   "metadata": {},
   "source": [
    "# 6. BASELINE RANDOM FOREST (CPU TRAINED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f509245",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(\n",
    "    n_estimators=400,\n",
    "    max_depth=40,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "train_pred = rf.predict(X_train)\n",
    "test_pred = rf.predict(X_test)\n",
    "\n",
    "print_metrics(y_train, train_pred, \"Baseline RF Train\")\n",
    "print_metrics(y_test, test_pred, \"Baseline RF Test\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6140ec",
   "metadata": {},
   "source": [
    "# 7. CROSS VALIDATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62604a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "cv_rmse_baseline = -cross_val_score(\n",
    "    baseline_rf,\n",
    "    X,\n",
    "    y,\n",
    "    cv=kf,\n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    ")\n",
    "cv_mae_baseline = -cross_val_score(\n",
    "    baseline_rf,\n",
    "    X,\n",
    "    y,\n",
    "    cv=kf,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    ")\n",
    "cv_r2_baseline = cross_val_score(\n",
    "    baseline_rf,\n",
    "    X,\n",
    "    y,\n",
    "    cv=kf,\n",
    "    scoring=\"r2\",\n",
    ")\n",
    "\n",
    "print(\"=== BASELINE RANDOM FOREST 5-FOLD CV ===\")\n",
    "print(f\"RMSE: mean={cv_rmse_baseline.mean():.4f}, std={cv_rmse_baseline.std():.4f}\")\n",
    "print(f\"MAE : mean={cv_mae_baseline.mean():.4f}, std={cv_mae_baseline.std():.4f}\")\n",
    "print(f\"R^2 : mean={cv_r2_baseline.mean():.4f}, std={cv_r2_baseline.std():.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d175a2",
   "metadata": {},
   "source": [
    "# 8. CONVERT SKLEARN RF â†’ PYTORCH RF (FOR GPU INFERENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea57a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nConverting Random Forest to PyTorch (MPS)...\")\n",
    "\n",
    "hb_model = convert(rf, \"pytorch\", X_train)\n",
    "\n",
    "hb_model.to(device)\n",
    "\n",
    "print(\"Conversion complete. Model is now on:\", device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817f451",
   "metadata": {},
   "source": [
    "# 9. GPU PREDICTION (MPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d62c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hummingbird.ml import convert\n",
    "\n",
    "print(\"\\nConverting Random Forest to PyTorch (MPS)...\")\n",
    "\n",
    "# Use NumPy array instead of DataFrame so Hummingbird treats it as a single input\n",
    "hb_model = convert(rf, \"pytorch\", X_train.values, device=device)\n",
    "\n",
    "print(\"Conversion complete. Model is now on:\", device)\n",
    "\n",
    "print(\"\\nRunning predictions on MPS...\")\n",
    "\n",
    "# Again, pass NumPy array here\n",
    "gpu_preds = hb_model.predict(X_test.values)  # returns numpy array\n",
    "\n",
    "print_metrics(y_test, gpu_preds, \"MPS RF Test (log_price)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabdc422",
   "metadata": {},
   "source": [
    "# 10. TEST SET EVALUATION \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21761be",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=gpu_preds, alpha=0.4)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \"r--\")\n",
    "plt.xlabel(\"Actual log_price\")\n",
    "plt.ylabel(\"Predicted log_price\")\n",
    "plt.title(\"Actual vs Predicted (MPS Random Forest)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "residuals = y_test - gpu_preds\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.histplot(residuals, kde=True, bins=40)\n",
    "plt.title(\"Residual Distribution (MPS RF)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7937dc4",
   "metadata": {},
   "source": [
    "# 11. FEATURE IMPORTANCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11c2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "feat_imp = pd.DataFrame({\"feature\": X.columns, \"importance\": importances})\n",
    "feat_imp = feat_imp.sort_values(\"importance\", ascending=False)\n",
    "\n",
    "print(\"Top 20 features:\")\n",
    "print(feat_imp.head(20))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=feat_imp.head(20), x=\"importance\", y=\"feature\")\n",
    "plt.title(\"Top 20 Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d935f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from hummingbird.ml import convert\n",
    "\n",
    "print(\"------------------------------------------------\")\n",
    "print(\"1. STARTING OPTUNA OPTIMIZATION\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "# 1. Define the Objective Function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 600),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 50),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 10),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        'max_features': trial.suggest_float('max_features', 0.5, 0.9),\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Train a quick model with these params\n",
    "    model = RandomForestRegressor(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on a validation set (here we use test set for speed in this demo)\n",
    "    # In strict ML, you might use a separate validation split or cross-val here\n",
    "    preds = model.predict(X_test)\n",
    "    return r2_score(y_test, preds)\n",
    "\n",
    "# 2. Run Optimization\n",
    "# Create a study to MAXIMIZE R^2\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)  # 15 trials to keep it relatively fast\n",
    "\n",
    "print(\"\\n------------------------------------------------\")\n",
    "print(f\"BEST PARAMS FOUND: {study.best_params}\")\n",
    "print(\"------------------------------------------------\")\n",
    "\n",
    "# 3. Train Final Model with Best Parameters\n",
    "print(\"\\nTraining Final Model with Best Parameters...\")\n",
    "best_rf = RandomForestRegressor(**study.best_params, n_jobs=-1, random_state=42)\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# 4. Convert to MPS (GPU) for Inference\n",
    "print(\"Converting to PyTorch (MPS)...\")\n",
    "hb_tuned = convert(best_rf, \"pytorch\", X_train.values, device=device)\n",
    "hb_tuned.to(device)\n",
    "\n",
    "# 5. Predict & Evaluate\n",
    "tuned_preds = hb_tuned.predict(X_test.values)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"========================================\")\n",
    "print(\"       RESULTS COMPARISON\")\n",
    "print(\"========================================\")\n",
    "\n",
    "# Use your previous 'test_pred' (CPU) or 'gpu_preds' (MPS) from Step 6/9 for comparison\n",
    "baseline_r2 = r2_score(y_test, gpu_preds) \n",
    "tuned_r2 = r2_score(y_test, tuned_preds)\n",
    "\n",
    "print(f\"Baseline R^2 : {baseline_r2:.5f}\")\n",
    "print(f\"Optuna R^2   : {tuned_r2:.5f}\")\n",
    "print(\"----------------------------------------\")\n",
    "print(f\"Improvement  : {tuned_r2 - baseline_r2:.5f}\")\n",
    "print(\"========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f6762",
   "metadata": {},
   "source": [
    "# 12. SUMMARY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ec24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== SUMMARY ===\")\n",
    "print(\"Baseline RF Test R^2:\", r2_score(y_test, test_pred))\n",
    "print(\"MPS RF Test R^2:\", r2_score(y_test, gpu_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
